#seda core config below

#separat with ";" if you have multi plugin paths
global.plugin.path=com.dingding.open.achelous.kafka.plugin

#step flow order. will be in order by default properties key declartion
msgCenter.stage=kafkaSub,comProc,kafkaPub

#from config.can use either "MQTYPE:TOPICNAME" or "TOPICNAME"(use kafka as default).
msgCenter.KAFKA_CONSUMER.from=my-replicated-topic

#zookeeper. only kakka need it. use localhost:2181?backup=localhost:3181 to ensure ha.
msgCenter.KAFKA_CONSUMER.zkconfig=192.168.200.128:2181

#kafka's group id. only consumer need to use it.
msgCenter.KAFKA_CONSUMER.group.id=consumer-seda-prop

#kafka's consumer threads.should less than partitions.
msgCenter.KAFKA_CONSUMER.streams=4

#core processor className.
msgCenter.COM_PROC.className=com.dingding.open.bigseda.processor.HelloWord

#scheduler. sync/async
msgCenter.COM_PROC.sync=async|io

#scheduler. realtime/crontab
msgCenter.COM_PROC.rt=realtime

#failover strategy
msgCenter.COM_PROC.fail=failover|3

#destination topic
msgCenter.KAFKA_PRODUCER.to=my-replicated-topic2
msgCenter.KAFKA_PRODUCER.brokers=192.168.200.128:9092

#msgCenter.syncPub  #use sync rpc invoke to transfer messages.

#msgCenter.localAsyncPub #use this to use thread pool for pushing data.